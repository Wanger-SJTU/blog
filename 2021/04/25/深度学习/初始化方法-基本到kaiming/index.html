<!DOCTYPE html>
<html lang="en">

<head>
	<meta http-equiv="content-type" content="text/html; charset=utf-8">
	<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
	
	<!-- title -->
	
	<title>
	
		初始化方法-基本到kaiming | 
	 
	Wang Er
	</title>
	
	<!-- keywords,description -->
	 

	<!-- favicon -->
	
	<link rel="shortcut icon" href="/blog/favicon.ico">
	


	<!-- search -->
	<script>
		var searchEngine = "https://www.google.com/search?q=";
		if(typeof searchEngine == "undefined" || searchEngine == null || searchEngine == ""){
			searchEngine = "https://www.google.com/search?q=";
		}
		var homeHost = "wanger-sjtu.github.io";
		if(typeof homeHost == "undefined" || homeHost == null || homeHost == ""){
			homeHost = window.location.host;
		}
	</script>


	
<link rel="stylesheet" href="/blog/css/main.css">

	
<link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css">

	
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.17.1/build/styles/darcula.min.css">

	
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">


	
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>

	
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>

	
<script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.17.1/build/highlight.min.js"></script>

	
<script src="https://cdn.jsdelivr.net/npm/jquery-pjax@2.0.1/jquery.pjax.min.js"></script>

	
<script src="/blog/js/main.js"></script>

	
		
<script src="https://cdn.jsdelivr.net/npm/leancloud-storage/dist/av-min.js"></script>

		
<script src="https://cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js"></script>

	
	
		<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
	<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?3efe99c287df5a1d6f0d02d187e403c1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

<header id="header">
    <a id="title" href="/blog/" class="logo">Wang Er</a>

	<ul id="menu">
		<li class="menu-item">
			<a href="/about" class="menu-item-link">ABOUT</a>
		</li>
	
		<li class="menu-item">
			<a href="/tags" class="menu-item-link">标签</a>
		</li>
	

	
		<li class="menu-item">
			<a href="/categories" class="menu-item-link">分类</a>
		</li>
	

		<li class="menu-item">
			<a href="https://github.com/wujun234/uid-generator-spring-boot-starter" class="menu-item-link" target="_blank">
				UidGenerator
			</a>
		</li>
		<li class="menu-item">
			<a href="https://github.com/wujun234" class="menu-item-link" target="_blank">
				<i class="fa fa-github fa-2x"></i>
			</a>
		</li>
	</ul>
</header>

	
<div id="sidebar">
	<button id="sidebar-toggle" class="toggle" ><i class="fa fa-arrow-right " aria-hidden="true"></i></button>
	
	<div id="site-toc">
		<input id="search-input" class="search-input" type="search" placeholder="按回车全站搜索">
		<div id="tree">
			

			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										c++
									</a>
									
							<ul>
								<li class="file">
									<a href="/blog/2019/04/03/c++/C++%20obj/">
										C++ obj
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/04/26/c++/C++%20%E5%88%9D%E5%A7%8B%E5%8C%96%E5%88%97%E8%A1%A8/">
										C++ 初始化列表
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/07/02/c++/C++%E8%B0%83%E7%94%A8tensorflow%E6%A8%A1%E5%9E%8B/">
										C++调用tensorflow模型
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										effective_modern_cpp
									</a>
									
							<ul>
								<li class="file">
									<a href="/blog/2021/04/20/c++/effective_modern_cpp/C++%E7%B1%BB%E5%9E%8B%E6%8E%A8%E5%AF%BC%E6%8E%A8%E5%80%92/">
										C++类型推导推倒
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/04/26/c++/%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0/">
										构造函数
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/04/26/c++/%E6%9F%94%E6%80%A7%E6%95%B0%E7%BB%84/">
										柔性数组
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										leetcode
									</a>
									
							<ul>
								<li class="file">
									<a href="/blog/2018/07/29/leetcode/1.2sum/">
										1.2sum
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/08/02/leetcode/121.%20Best%20Time%20to%20Buy%20and%20Sell%20Stock%20/">
										121. Best Time to Buy and Sell Stock 
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/09/06/leetcode/122.%20Best%20Time%20to%20Buy%20and%20Sell%20Stock%20II/">
										122. Best Time to Buy and Sell Stock II
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/07/29/leetcode/2.%20add%202%20numbers/">
										2. add 2 numbers
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/07/29/leetcode/3.%20Longest%20Substring%20Without%20Repeating%20Characters/">
										3. Longest Substring Without Repeating Characters
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/09/09/leetcode/5.Longest%20Palindromic%20Substring/">
										5.Longest Palindromic Substring
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/09/15/leetcode/516.%20Longest%20Palindromic%20Subsequence/">
										516. Longest Palindromic Subsequence
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/09/07/leetcode/53.%20Maximum%20Subarray/">
										53. Maximum Subarray
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/09/05/leetcode/70.Climbing%20Stairs/">
										70.Climbing Stairs
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/07/28/leetcode/93.Restore%20IP%20Addresses/">
										93.Restore IP Addresses
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/02/06/leetcode/House%20Robber/">
										House Robber
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/04/02/leetcode/Integer%20to%20Roman/">
										Integer to Roman
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/04/03/leetcode/LCS/">
										LCS
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/08/03/leetcode/Min%20Cost%20Climbing%20Stairs/">
										Min Cost Climbing Stairs
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/07/29/leetcode/Product%20of%20Array%20Except%20Self%20%E9%99%A4%E6%9C%AC%E8%BA%AB%E4%B9%8B%E5%A4%96%E7%9A%84%E6%95%B0%E7%BB%84%E4%B9%8B%E7%A7%AF/">
										Product of Array Except Self 除本身之外的数组之积
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/04/02/leetcode/Roman%20to%20Integer/">
										Roman to Integer
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/04/13/leetcode/add_digits/">
										add_digits
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/04/02/leetcode/baidu0402/">
										baidu0402
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/04/02/leetcode/container-with-most-water/">
										container-with-most-water
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/03/16/leetcode/lru%20cache/">
										lru cache
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/04/02/leetcode/max_prefix/">
										max_prefix
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2017/04/25/leetcode/midianValue2sortedArray/">
										midianValue2sortedArray
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/04/04/leetcode/next_array/">
										next_array
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/03/18/leetcode/subset_sum/">
										subset_sum
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/07/23/leetcode/%E9%93%BE%E8%A1%A8%E5%8F%8D%E8%BD%AC/">
										链表反转
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										python
									</a>
									
							<ul>
								<li class="file">
									<a href="/blog/2018/06/27/python/2018-06-27-numpy%E6%8C%87%E5%8C%97/">
										2018-06-27-numpy指北
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/09/01/python/2018-09-01-python%E5%A4%9A%E7%BA%BF%E7%A8%8B/">
										2018-09-01-python多线程
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/10/23/python/2018-10-23-import%20cv2%20error/">
										2018-10-23-import cv2 error
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/03/25/python/2019-03-25-pythondecorator/">
										2019-03-25-pythondecorator
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										公开课
									</a>
									
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										mit6.s081
									</a>
									
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										labs
									</a>
									
							<ul>
								<li class="file">
									<a href="/blog/2021/04/25/%E5%85%AC%E5%BC%80%E8%AF%BE/mit6.s081/labs/1%20util/">
										1 util
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2021/04/25/%E5%85%AC%E5%BC%80%E8%AF%BE/mit6.s081/labs/lab03/">
										lab03
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2021/04/25/%E5%85%AC%E5%BC%80%E8%AF%BE/mit6.s081/labs/lab04/">
										lab04
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										课程笔记
									</a>
									
							<ul>
								<li class="file">
									<a href="/blog/2021/04/25/%E5%85%AC%E5%BC%80%E8%AF%BE/mit6.s081/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/0%20tools/">
										0 tools
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2021/04/25/%E5%85%AC%E5%BC%80%E8%AF%BE/mit6.s081/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/lab03/">
										lab03
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
								</li>
								
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										其他
									</a>
									
							<ul>
								<li class="file">
									<a href="/blog/2018/04/12/%E5%85%B6%E4%BB%96/2018-04-12-v2ray/">
										2018-04-12-v2ray
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										深度学习
									</a>
									
							<ul>
								<li class="file">
									<a href="/blog/2019/03/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2d3D%20alignment/">
										2d3D alignment
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/07/22/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Adapt%20SegNet/">
										Adapt SegNet
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/09/27/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CAM/">
										CAM
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/07/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CYCADA/">
										CYCADA
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/04/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CrossEntrophy/">
										CrossEntrophy
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/05/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/DML%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">
										DML阅读笔记
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/07/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/FCAN/">
										FCAN
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/09/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/ML_DL%20%E5%88%86%E5%B8%83%E5%BA%A6%E9%87%8F/">
										ML_DL 分布度量
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/08/11/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Multi-path%20Learning%20for%20Object%20Pose%20Estimation%20Across%20Domains/">
										Multi-path Learning for Object Pose Estimation Across Domains
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/PSP%20Network/">
										PSP Network
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/03/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/PTCN/">
										PTCN
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/03/23/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/PVnet/">
										PVnet
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/03/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/RANSACsample/">
										RANSACsample
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/06/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/STN_CTC/">
										STN_CTC
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/07/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/activation%20normalization%20layer/">
										activation normalization layer
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/08/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/global%20average%20pooling/">
										global average pooling
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/09/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/instance%20norm/">
										instance norm
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/07/17/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/loss%20function/">
										loss function
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2021/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/normalization%20layer/">
										normalization layer
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/09/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/print%20%E6%A2%AF%E5%BA%A6/">
										print 梯度
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/09/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/python%20%E8%A3%85%E9%A5%B0%E5%99%A8/">
										python 装饰器
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/10/11/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/show%20attend%20tell/">
										show attend tell
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2019/03/11/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/training%20ImageNet%201%20hour/">
										training ImageNet 1 hour
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file active">
									<a href="/blog/2021/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B9%E6%B3%95-%E5%9F%BA%E6%9C%AC%E5%88%B0kaiming/">
										初始化方法-基本到kaiming
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/blog/2018/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%BA%A6%E9%87%8F/">
										语义分割度量
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
		</div>
	</div>
</div>

	<!-- 引入正文 -->
	<div id="content">
		<h1 id="article-title">

	初始化方法-基本到kaiming
</h1>
<div class="article-meta">
	
		<span>
			阅读量:<span id="/blog/2021/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B9%E6%B3%95-%E5%9F%BA%E6%9C%AC%E5%88%B0kaiming/" class="leancloud_visitors" data-flag-title="初始化方法-基本到kaiming"></span>
		</span>
	
	<span>王二</span>
	<span>2021-04-25 17:39:19</span>
		<div id="article-categories">
    
		<span>Categories：</span>
            
    

    
		<span>Tags：</span>
            
                
                    <span>
                        <i class="fa fa-tag" aria-hidden="true">
                        <a href="/tags/DL/">DL</a>
                        </i>
                    </span>
                
            
    
		</div>

</div>

<div id="article-content">
	<h3 id="为什么需要初始化"><a href="#为什么需要初始化" class="headerlink" title="为什么需要初始化"></a>为什么需要初始化</h3><p>初始化的原因，</p>
<ul>
<li>防止每一层的输出太大或者太小，导致梯度反向传播过程中，梯度爆炸或者梯度消失。</li>
<li>不能采用统一值得原因，因为统一值得初始化会使得每一层网络在不同通道学到得特征相同。</li>
</ul>
<p>上述原因都会导致，网络模型不能收敛。</p>
<h4 id="简单例子得说明"><a href="#简单例子得说明" class="headerlink" title="简单例子得说明"></a>简单例子得说明</h4><p>假如我们有一个输入<code>x</code> ，定义为</p>
<pre><code class="lang-python">&gt;&gt;&gt; x = torch.randn(512)
</code></pre>
<p><code>x</code>是`均值为 $0$，方差是 $1$ 的高斯分布。然后定义一个100层的神经网络（注：不包含激活函数）</p>
<pre><code class="lang-python">for i in range(100):
    a = torch.randn(512,512)
    x = a @ x
print(x.mean(), x.std())
</code></pre>
<p>那么得到</p>
<pre><code class="lang-python">(tensor(nan),tensor(nan))
</code></pre>
<p>输出已经是无穷大了。通过下面的代码，可以知道大概29层以后，输出就已经无法计算了</p>
<pre><code class="lang-python">for i in range(100):
    a = torch.randn(512,512)
    x = a @ x
    if torch.isnan(x.std()):
        break
print(i) # 28
</code></pre>
<p>既然输出太大，我们把神经网络的初始化变小一点。</p>
<pre><code class="lang-python">for i in range(100):
    a = torch.randn(512,512)*0.01
    x = a @ x
print(x.mean(), x.std())
# 0, 0
</code></pre>
<p>那么得到</p>
<pre><code class="lang-python">(tensor(0.),tensor(0.))
</code></pre>
<p>这时候的输出就太小，没办法计算了。</p>
<h3 id="怎么找到合适的初始化方法"><a href="#怎么找到合适的初始化方法" class="headerlink" title="怎么找到合适的初始化方法"></a>怎么找到合适的初始化方法</h3><p>对于神经网络来说，前向传播过程就是矩阵运算，假设一层的输出为$y$</p>
<script type="math/tex; mode=display">
y_i= \sum_{k=1}^{n-1}a_{i,k}x_k</script><p>$i$ 是矩阵 $\mathbf{m}$ 的行，$k$ 是矩阵 $\mathbf{m}$ 的列。python的计算代码</p>
<pre><code class="lang-python">y[i] = sum([c*d for c,d in zip(a[i], x)])
</code></pre>
<p>可以证明，在给定的层，从标准正态分布初始化的输入$x$ 和权重矩阵 $a$ 的矩阵乘积平均具有非常接近输入<strong>连接数的平方根的标准偏差</strong>，在例子中是$\sqrt{512}$。</p>
<pre><code class="lang-python">mean,var=0.,0.
for i in range(10000):
    x = torch.randn(512)
    a = torch.randn(512,512)
    y = a @ x
    mean += y.mean().item()
    var += y.pow(2).mean().item()
print(mean()/10000, math.sqrt(var/10000))
#0.00889449315816164  22.629779825053976
print(math.sqrt(512))
# 22.627416997969522

mean,var = 0.,0.
for i in range(10000):
    x = torch.randn(512)
    a = torch.randn(512,512)
    b = torch.randn(512,512)
    y = a @ x
    z = b @ y
    mean += z.mean().item()
    var += z.pow(2).mean().item()
print(mean/10000, math.sqrt(var/10000))
#0.6010947234869003 511.8684602024235
</code></pre>
<p>如果我们根据如何定义矩阵乘法来看前向传播的过程：</p>
<p>为了计算 $y$，我们将输入 $x$ 的一个元素的乘以矩阵 $\mathbf{a}$ 的一列的512个乘积然后相加。在使用标准正态分布初始化$x$ 和 $a$ 的示例中，这$512$ 个数字中的每一个的平均值为 $0$，标准差为$1$。</p>
<blockquote>
<p><strong>经过一层网络运算以后，均值没变，方差扩大了$\sqrt{512}$倍。</strong></p>
</blockquote>
<p>因此在初始化的是，缩小$\sqrt{512}$倍，那么输出结果就能保证不<strong>爆炸</strong>了。</p>
<pre><code class="lang-python">mean,var=0.,0.
for i in range(10000):
    x = torch.randn(512)
    a = torch.randn(512,512)/math.sqrt(512)
    y = a @ x
    mean += y.mean().item()
    var += y.pow(2).mean().item()
print(mean/10000, math.sqrt(var/10000))
#0.00039810733370250094 1.0007971983717594
</code></pre>
<pre><code class="lang-python">x = torch.randn(512)
for i in range(100):
    a = torch.randn(512,512)/math.sqrt(512)
    x = a @ x
print(x.mean(), x.std())
#tensor(-0.0048) tensor(1.2810)
</code></pre>
<h3 id="Xavier-Initialization"><a href="#Xavier-Initialization" class="headerlink" title="Xavier Initialization"></a>Xavier Initialization</h3><p>上面介绍的情况是在不含有激活的函数情形，如果增加了激活函数，是否仍能保持不变呢？对于不同类型的激活函数，是不是有不同的表现呢？最开始用的激活函数多数为对称的，并且导数从中间到两边有递减为0。比如，常用的<code>tanh</code>和<code>sigmoid</code>函数。</p>
<p>下面的结果是在上面的例子中分别增加了，<code>tanh</code>和<code>sigmoid</code>函数的结果。</p>
<pre><code class="lang-python">#sigmoid
x = torch.randn(512)
for i in range(100):
    a = torch.randn(512,512)/math.sqrt(512)
    x = torch.sigmoid( a @ x)
print(x.mean(), x.std())
#tensor(0.5057) tensor(0.1180)
</code></pre>
<pre><code class="lang-python">#tanh
x = torch.randn(512)
for i in range(100):
    a = torch.randn(512,512)/math.sqrt(512)
    x =  torch.tanh( a @ x)
print(x.mean(), x.std())
#tensor(-0.0051) tensor(0.0879)
</code></pre>
<p>可以看到经过激活函数以后，函数方差明显变小了。在训练过程中这就会导致，导致梯度过小，使得训练难以进行。</p>
<p>上面用的是正态分布，如果采用均匀分布呢？</p>
<pre><code class="lang-python">x = torch.randn(512)
for i in range(100):
    a = torch.Tensor(512,512).uniform_(-1,1)/math.sqrt(512)
    x =  torch.tanh( a @ x)
print(x.mean(), x.std())
#tensor(-3.8077e-26) tensor(1.2476e-24)
</code></pre>
<pre><code class="lang-python">x = torch.randn(512)
for i in range(100):
    a = torch.Tensor(512,512).uniform_(0,1)/math.sqrt(512)
    x =  torch.tanh( a @ x)
print(x.mean(), x.std())
#tensor(-1.) tensor(0.)
</code></pre>
<pre><code class="lang-python">x = torch.randn(512)
for i in range(100):
    a = torch.Tensor(512,512).uniform_(0,1)/math.sqrt(512)
    x =  torch.sigmoid( a @ x)
print(x.mean(), x.std())
#tensor(1.0000) tensor(3.8114e-06)
</code></pre>
<pre><code class="lang-python">x = torch.randn(512)
for i in range(100):
    a = torch.Tensor(512,512).uniform_(-1,1)/math.sqrt(512)
    x =  torch.sigmoid( a @ x)
print(x.mean(), x.std())
#tensor(0.4934) tensor(0.0659)
</code></pre>
<p>方差都出人意料的小。这就几乎不能学习到什么有用的特征了。</p>
<p>为此，Glorot and Bengio 提出了<code>Xavier initialization</code>的初始化方式</p>
<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>这种初始化方式是从随机均匀分布初始化神经网络的，均匀分布的范围是</p>
<script type="math/tex; mode=display">
\pm \frac{\sqrt{6}}{\sqrt{n_i+n_{i+1}}}</script><p>这里的 $n<em>i$ 是输入神经元数目，$n</em>{i+1}$ 是输出神经元数目。</p>
<p>Glorot and Bengio 认为Xavier 初始化方法，可以在包含激活函数的神经网络中保持方差的变化很小。</p>
<p><img src="https://tuchuang-1259359185.cos.ap-chengdu.myqcloud.com/bolgs/Xavier.png" alt="img"></p>
<p>除此之外，同样证明了，传统方法在底层网络方差大，高层网络方差趋近于0的现象。</p>
<p><img src="https://tuchuang-1259359185.cos.ap-chengdu.myqcloud.com/bolgs/Xavier2.png" alt=""></p>
<pre><code class="lang-python">def xavier(m,n):
    return torch.Tensor(m,n).uniform_(-1,1)/math.sqrt(6./(m+n))

x = torch.randn(512)
for i in range(100):
    a = xavier(512,512)
    x =  torch.tanh( a @ x)
print(x.mean(), x.std())
#tensor(0.0854) tensor(0.9933)
x = torch.randn(512)
for i in range(100):
    a = xavier(512,512)
    x =  torch.sigmoid( a @ x)
print(x.mean(), x.std())
#tensor(0.4686) tensor(0.4976)
</code></pre>
<h3 id="Kaiming-Initialization"><a href="#Kaiming-Initialization" class="headerlink" title="Kaiming Initialization"></a>Kaiming Initialization</h3><p>进来CV领域中，激活方法多是采用<code>Relu</code> 函数。对于这个函数。之前的初始化方法，又有哪些不一样？</p>
<pre><code class="lang-python">x = torch.randn(512)
for i in range(100):
    a = torch.randn(512,512)/math.sqrt(512)
    x = torch.relu(a @ x)
print(x.mean(), x.std())
# tensor(4.6656e-16) tensor(6.7154e-16)
</code></pre>
<pre><code class="lang-python">x = torch.randn(512)
for i in range(100):
    a = xavier(512,512)
    x =  torch.relu( a @ x)
print(x.mean(), x.std())
# tensor(nan) tensor(nan)
</code></pre>
<p>之前的初始化方法，对于<code>Relu</code>函数都不奏效了。那对于每一层来说，有什么变化</p>
<pre><code class="lang-python">mean,var=0.,0.
for i in range(10000):
    x = torch.randn(512)
    a = torch.randn(512,512)/math.sqrt(512)
    y = torch.relu(a @ x)
    mean += y.mean().item()
    var += y.pow(2).mean().item()

print(mean/10000, math.sqrt(var/10000))
#9.01142036409378 15.991211348807246
print(math.sqrt(512/2))
#16.0
</code></pre>
<p>可以看到，这时候的输出跟输入网络层数大小是有关系的。在下面的实验验证以下。</p>
<pre><code class="lang-python">mean,var=0.,0.
for i in range(10000):
    x = torch.randn(512)
    a = torch.randn(512,512)/math.sqrt(512/2.)
    y = torch.relu(a @ x)
    mean += y.mean().item()
    var += y.pow(2).mean().item()

print(mean/10000, math.sqrt(var/10000))
#0.5640919140070677 1.0003173674661943
</code></pre>
<pre><code class="lang-python">def kaiming(m,n):
    return torch.randn(m,n)*math.sqrt(2./m)

x = torch.randn(512)
for i in range(100):
    a = kaiming(512,512)
    x = torch.relu( a @ x)
print(x.mean(), x.std())
# tensor(0.8135) tensor(1.2431)
</code></pre>
<p>对照本部分开始的结果<code>kaiming</code>方法在对于<code>Relu</code>函数更有优势。</p>
<p>下图给出了两种方法在一个30层CNN上的结果。</p>
<p><img src="https://tuchuang-1259359185.cos.ap-chengdu.myqcloud.com/bolgs/kaiming.png" alt="kaiming method"></p>
<hr>
<p><strong>来源</strong>  <a target="_blank" rel="noopener" href="https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79">Weight Initialization in Neural Networks: A Journey From the Basics to Kaiming</a></p>

</div>


    <div class="post-guide">
        <div class="item left">
            
              <a href="/blog/2021/04/25/%E5%85%AC%E5%BC%80%E8%AF%BE/mit6.s081/labs/1%20util/">
                  <i class="fa fa-angle-left" aria-hidden="true"></i>
                  mit6.s081
              </a>
            
        </div>
        <div class="item right">
            
              <a href="/blog/2021/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/normalization%20layer/">
                normalization layer
                <i class="fa fa-angle-right" aria-hidden="true"></i>
              </a>
            
        </div>
    </div>



	<div id="vcomments"></div>


<script>
	
		// 评论
		new Valine({
			av: AV,
			el: '#vcomments',
			notify: false,
			verify: false,
			path: window.location.pathname,
			appId: '5PQlnuuLOrt9dJRqxghztqVb-gzGzoHsz',
			appKey: 'V5LIjFblR0zzysVlR0lbmp0o',
			placeholder: '请输入评论',
			avatar: 'retro',
			recordIP: false
		})
	
	
    // 显示次数
		function showTime(Counter) {
			var query = new AV.Query("Counter");
			if($(".leancloud_visitors").length > 0){
				var url = $(".leancloud_visitors").attr('id').trim();
				// where field
				query.equalTo("words", url);
				// count
				query.count().then(function (number) {
					// There are number instances of MyClass where words equals url.
					$(document.getElementById(url)).text(number?  number : '--');
				}, function (error) {
					// error is an instance of AVError.
				});
			}
		}
		// 追加pv
		function addCount(Counter) {
			var url = $(".leancloud_visitors").length > 0 ? $(".leancloud_visitors").attr('id').trim() : 'wujun234.github.io';
			var Counter = AV.Object.extend("Counter");
			var query = new Counter;
			query.save({
				words: url
			}).then(function (object) {
			})
		}
		$(function () {
			var Counter = AV.Object.extend("Counter");
			addCount(Counter);
			showTime(Counter);
		});
	
</script>
	</div>
	<div id="footer">
	<p>
	©2018-<span id="footerYear"></span> 
	<a href="/">王二</a> 
	
	
		|
		<span id="busuanzi_container_site_pv">
			pv
			<span id="busuanzi_value_site_pv"></span>
		</span>
		|
		<span id="busuanzi_container_site_uv"> 
			uv
			<span id="busuanzi_value_site_uv"></span>
		</span>
	
	<br>
	Theme <a href="//github.com/wujun234/hexo-theme-tree" target="_blank">Tree</a>
	by <a href="//github.com/wujun234" target="_blank">WuJun</a>
	Powered by <a href="//hexo.io" target="_blank">Hexo</a>
	</p>
</div>
<script type="text/javascript"> 
	document.getElementById('footerYear').innerHTML = new Date().getFullYear() + '';
</script>
	<button id="totop-toggle" class="toggle"><i class="fa fa-angle-double-up" aria-hidden="true"></i></button>
</body>
</html>